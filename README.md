# MultiModel GPT

A powerful web application to compare responses from multiple AI models side-by-side, with **persistent conversation history** and **project-level memory** that preserves context across sessions.

![Next.js](https://img.shields.io/badge/Next.js-16-black?style=flat-square&logo=next.js)
![TypeScript](https://img.shields.io/badge/TypeScript-5-blue?style=flat-square&logo=typescript)
![Tailwind CSS](https://img.shields.io/badge/Tailwind-4-38B2AC?style=flat-square&logo=tailwind-css)
![SQLite](https://img.shields.io/badge/SQLite-3-003B57?style=flat-square&logo=sqlite)

## âœ¨ Features

### ğŸ“ Project-Based Workflow
- **Create Projects**: Organize your AI comparisons into separate projects
- **Conversation Threads**: Multiple conversations within each project
- **Full History Persistence**: Every question, every model response, and every verdict is saved
- **Resume Anytime**: Open a thread and see your complete conversation history
- **Context Preservation**: All models receive project context for more relevant responses

### ğŸ”„ MultiAsk Mode
- **Parallel Querying**: Send your question to multiple LLM models simultaneously
- **Streaming Responses**: Watch responses appear in real-time as models generate them
- **Side-by-Side Comparison**: View all model responses in a responsive grid layout
- **Verdict Synthesis**: An optional verdict model analyzes all responses to identify consensus and differences
- **Follow-up Conversations**: Continue asking questions with full conversation context
- **Complete History**: See all past turns with questions, responses from every model, and verdicts

### ğŸ” Critique Chain Mode
A structured workflow for thoroughly vetted answers:

| Step | Description |
|------|-------------|
| 1. **Primary Model** | Answers your question first |
| 2. **Critique Models** | Multiple models critically evaluate the primary response for accuracy, completeness, and reasoning |
| 3. **Reviewer Model** | Synthesizes all critiques, identifies consensus/disagreements, and provides a final verdict |

- **Visual Progress**: See which step is currently active
- **Follow-up Support**: Continue with follow-up questions that include full context
- **History Persistence**: All steps are saved and visible when you return to the thread

### ğŸ§  Smart Memory System
- **Automatic Summarization**: Every 10 messages, an AI analyzes conversations and extracts:
  - **Summary**: Overview of project status and goals
  - **Key Facts**: Important information established in conversations
  - **Decisions**: Choices made with reasoning and dates
  - **Open Questions**: Unresolved items to address
- **Context Injection**: Project memory is included in prompts to all models
- **Manual Refresh**: Trigger memory updates on demand

### ğŸ¨ Modern UI/UX
- Beautiful dark theme with gradient accents
- Responsive sidebar with project and thread navigation
- Markdown rendering with syntax highlighting
- Real-time streaming animations
- Auto-expanding text input
- Loading states and smooth transitions

## ğŸš€ Quick Start

### Prerequisites

- **Node.js 18+** - [Download here](https://nodejs.org/)
- **OpenRouter API Key** - [Get one here](https://openrouter.ai/keys)

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/dsk003/multimodelGPT.git
   cd multimodelGPT
   ```

2. **Install dependencies**
   ```bash
   npm install
   ```

3. **Start the development server**
   ```bash
   npm run dev
   ```

4. **Open the app**
   
   Navigate to [http://localhost:3000](http://localhost:3000) in your browser.

5. **Configure your API key**
   - Click the **Settings** button (top right)
   - Paste your OpenRouter API key
   - Add model IDs for the modes you want to use

6. **Create a Project & Start Comparing**
   - Click the **+** button in the sidebar to create a project
   - Click **MultiAsk** or **Critique Chain** to start a conversation
   - Ask your question and watch the magic happen!

## âš™ï¸ Configuration

### Setting Up Models

Click **Settings** in the top right corner to configure:

#### API Key
| Setting | Description |
|---------|-------------|
| **OpenRouter API Key** | Your API key from [openrouter.ai/keys](https://openrouter.ai/keys) |

#### MultiAsk Tab
| Setting | Description |
|---------|-------------|
| **Models to Query** | Add model IDs to compare (e.g., `openai/gpt-4o`). Add multiple models to see responses side-by-side. |
| **Verdict Model** | (Optional) A model that synthesizes all responses and identifies consensus/differences |

#### Critique Chain Tab
| Setting | Description |
|---------|-------------|
| **Primary Model** | The model that answers your question first |
| **Critique Models** | Models that critically evaluate the primary response (add 2-3 for diverse perspectives) |
| **Reviewer Model** | Model that synthesizes all critiques into a final assessment |

### Finding Model IDs

Browse available models at [openrouter.ai/models](https://openrouter.ai/models). Click any model to see its ID.

#### Popular Model IDs

| Model | ID | Best For |
|-------|-----|----------|
| GPT-4o | `openai/gpt-4o` | Complex reasoning, analysis |
| GPT-4o Mini | `openai/gpt-4o-mini` | Fast, cost-effective responses |
| Claude 3.5 Sonnet | `anthropic/claude-3.5-sonnet` | Writing, coding, analysis |
| Claude 3.5 Haiku | `anthropic/claude-3.5-haiku` | Fast, concise responses |
| Gemini 2.0 Flash | `google/gemini-2.0-flash-exp:free` | Free tier, general use |
| Gemini 1.5 Pro | `google/gemini-pro-1.5` | Long context, detailed responses |
| Llama 3.3 70B | `meta-llama/llama-3.3-70b-instruct` | Open source, capable |
| DeepSeek V3 | `deepseek/deepseek-chat` | Coding, reasoning |
| Qwen 2.5 72B | `qwen/qwen-2.5-72b-instruct` | Multilingual, reasoning |

## ğŸ“– How to Use

### Creating a Project

1. Click the **+** button in the sidebar
2. Enter a project name (e.g., "Research on AI", "Code Review", "Writing Help")
3. Click **Create**

### Starting a Conversation

1. Select your project in the sidebar
2. Click **MultiAsk** or **Critique Chain** button
3. Enter a title for your conversation
4. Start asking questions!

### MultiAsk Workflow

1. **Type your question** in the input box
2. **Press Enter** or click the send button
3. **Watch responses stream** in from all configured models
4. **Review the verdict** (if configured) for synthesis
5. **Ask follow-ups** to continue the conversation

### Critique Chain Workflow

1. **Type your question** in the input box
2. **Watch the primary model** answer first
3. **See critiques** from each critique model
4. **Read the final review** synthesizing all perspectives
5. **Ask follow-ups** for deeper exploration

### Viewing History

- **Select any thread** in the sidebar to see its complete history
- **All turns are preserved**: questions, model responses, verdicts/reviews
- **Continue where you left off** by asking a new question

### Managing Projects

- **Switch projects**: Click a project name in the sidebar
- **View threads**: Threads appear under the selected project
- **Delete threads**: Hover over a thread and click the trash icon
- **Delete projects**: Hover over a project and click the trash icon (deletes all threads too)

## ğŸ§  Project Memory System

### How It Works

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Your Conversations                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚ Message â”‚  â”‚ Message â”‚  â”‚ Message â”‚  â”‚ Message â”‚  ...    â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜        â”‚
â”‚       â”‚            â”‚            â”‚            â”‚              â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                          â”‚                                   â”‚
â”‚                          â–¼                                   â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚              â”‚   Every 10 Messages   â”‚                      â”‚
â”‚              â”‚   AI Summarization    â”‚                      â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚                          â”‚                                   â”‚
â”‚                          â–¼                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                   Project Memory                       â”‚  â”‚
â”‚  â”‚  â€¢ Summary: Project overview and status               â”‚  â”‚
â”‚  â”‚  â€¢ Facts: Key information established                 â”‚  â”‚
â”‚  â”‚  â€¢ Decisions: Choices made with reasoning             â”‚  â”‚
â”‚  â”‚  â€¢ Open Questions: Items to address                   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                          â”‚                                   â”‚
â”‚                          â–¼                                   â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚              â”‚   Injected into all   â”‚                      â”‚
â”‚              â”‚   future prompts      â”‚                      â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Memory Display

- **View memory** in the sidebar under the current project
- **Refresh memory** by clicking the refresh button
- **Memory updates** automatically every 10 messages

## ğŸ“ Project Structure

```
multimodelGPT/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â”œâ”€â”€ chat/route.ts              # OpenRouter API proxy
â”‚   â”‚   â”‚   â”œâ”€â”€ projects/                  # Project CRUD endpoints
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ route.ts               # List/Create projects
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ [id]/
â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ route.ts           # Get/Update/Delete project
â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ threads/route.ts   # List/Create threads
â”‚   â”‚   â”‚   â”‚       â””â”€â”€ memory/route.ts    # Get/Refresh memory
â”‚   â”‚   â”‚   â””â”€â”€ threads/
â”‚   â”‚   â”‚       â””â”€â”€ [id]/
â”‚   â”‚   â”‚           â”œâ”€â”€ route.ts           # Get/Update/Delete thread
â”‚   â”‚   â”‚           â””â”€â”€ messages/route.ts  # Get/Save messages
â”‚   â”‚   â”œâ”€â”€ globals.css
â”‚   â”‚   â”œâ”€â”€ layout.tsx
â”‚   â”‚   â””â”€â”€ page.tsx                       # Main app with routing
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ CritiqueChain.tsx              # Critique Chain workflow
â”‚   â”‚   â”œâ”€â”€ FollowUpInput.tsx              # Follow-up input component
â”‚   â”‚   â”œâ”€â”€ NewThreadModal.tsx             # Create thread modal
â”‚   â”‚   â”œâ”€â”€ ProjectSidebar.tsx             # Sidebar navigation
â”‚   â”‚   â”œâ”€â”€ ResponsePanel.tsx              # Model response display
â”‚   â”‚   â”œâ”€â”€ SettingsModal.tsx              # Settings configuration
â”‚   â”‚   â””â”€â”€ VerdictPanel.tsx               # Verdict/synthesis display
â”‚   â”œâ”€â”€ context/
â”‚   â”‚   â”œâ”€â”€ ModelsContext.tsx              # Model settings state
â”‚   â”‚   â””â”€â”€ ProjectContext.tsx             # Project/thread state
â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”œâ”€â”€ index.ts                       # SQLite connection & migrations
â”‚   â”‚   â””â”€â”€ schema.ts                      # Drizzle ORM schema
â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”œâ”€â”€ context-manager.ts             # Memory management
â”‚   â”‚   â””â”€â”€ conversation-utils.ts          # History reconstruction
â”‚   â””â”€â”€ types/
â”‚       â””â”€â”€ index.ts                       # TypeScript types
â”œâ”€â”€ data/                                  # SQLite database (auto-created)
â”‚   â””â”€â”€ multimodel.db
â”œâ”€â”€ package.json
â”œâ”€â”€ tailwind.config.ts
â””â”€â”€ tsconfig.json
```

## ğŸ—„ï¸ Database Schema

```sql
-- Projects: Top-level organization
projects (id, name, created_at, updated_at)

-- Project Memory: AI-generated context
project_memory (id, project_id, summary, facts, decisions, open_questions, updated_at)

-- Threads: Conversations within projects
threads (id, project_id, title, mode, created_at, updated_at)

-- Messages: Individual messages with turn grouping
messages (id, thread_id, project_id, role, content, model_used, turn_number, metadata, created_at)
```

## ğŸ› ï¸ Tech Stack

| Technology | Purpose |
|------------|---------|
| [Next.js 16](https://nextjs.org/) | React framework with App Router |
| [TypeScript](https://www.typescriptlang.org/) | Type-safe JavaScript |
| [Tailwind CSS](https://tailwindcss.com/) | Utility-first styling |
| [SQLite](https://www.sqlite.org/) | Local database storage |
| [better-sqlite3](https://github.com/WiseLibs/better-sqlite3) | SQLite driver |
| [Drizzle ORM](https://orm.drizzle.team/) | Type-safe database queries |
| [OpenRouter](https://openrouter.ai/) | Unified LLM API access |
| [React Markdown](https://github.com/remarkjs/react-markdown) | Markdown rendering |
| [remark-gfm](https://github.com/remarkjs/remark-gfm) | GitHub Flavored Markdown |

## ğŸ“ Usage Tips

### For Best Results

| Tip | Description |
|-----|-------------|
| **Diverse Models** | Use models from different providers for varied perspectives |
| **Capable Verdict** | Use a strong model (GPT-4o, Claude 3.5 Sonnet) as verdict/reviewer |
| **Project Per Topic** | Create separate projects for different research topics |
| **Clear Questions** | Be specific in your questions for better responses |
| **Follow Up** | Use follow-up questions to drill deeper into topics |

### Recommended Model Combinations

**For MultiAsk Comparison:**
- GPT-4o + Claude 3.5 Sonnet + Gemini 1.5 Pro
- GPT-4o-mini + Claude 3.5 Haiku + Llama 3.3 70B (cost-effective)

**For Critique Chain:**
- Primary: GPT-4o or Claude 3.5 Sonnet
- Critics: 2-3 models from different providers
- Reviewer: GPT-4o or Claude 3.5 Sonnet

## ğŸ› Troubleshooting

### Common Issues

| Issue | Solution |
|-------|----------|
| **"API key invalid"** | Ensure key starts with `sk-or-` and has credits |
| **Models not responding** | Check model ID is correct at openrouter.ai/models |
| **Database errors** | Delete `data/multimodel.db` to reset |
| **Slow responses** | Some models are slower; try faster variants |
| **Memory not updating** | Click "Refresh Memory" in sidebar |

### Reset Everything

```bash
# Delete the database to start fresh
rm -rf data/multimodel.db*

# Restart the server
npm run dev
```

## ğŸ”® Future Ideas

- [ ] Export conversations to Markdown/PDF
- [ ] Custom system prompts per project
- [ ] Model response rating/feedback
- [ ] Cost tracking per conversation
- [ ] Sharing threads with others
- [ ] Custom themes

## ğŸ“„ License

MIT License - feel free to use this project for any purpose.

---

<p align="center">
  <strong>Made with â¤ï¸ for the AI community</strong>
  <br>
  <a href="https://github.com/dsk003/multimodelGPT">GitHub</a> â€¢
  <a href="https://openrouter.ai/">OpenRouter</a>
</p>
