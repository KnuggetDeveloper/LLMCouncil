# MultiModel GPT

A powerful web application to compare responses from multiple AI models side-by-side, with **persistent conversation history** and **project-level memory** that preserves context across sessions.

![Next.js](https://img.shields.io/badge/Next.js-16-black?style=flat-square&logo=next.js)
![TypeScript](https://img.shields.io/badge/TypeScript-5-blue?style=flat-square&logo=typescript)
![Tailwind CSS](https://img.shields.io/badge/Tailwind-4-38B2AC?style=flat-square&logo=tailwind-css)
![SQLite](https://img.shields.io/badge/SQLite-3-003B57?style=flat-square&logo=sqlite)

## âœ¨ Features

### ğŸ“ Project-Based Workflow

- **Create Projects**: Organize your AI comparisons into separate projects
- **Conversation Threads**: Multiple conversations within each project
- **Full History Persistence**: Every question, every model response, and every verdict is saved
- **Resume Anytime**: Open a thread and see your complete conversation history
- **Context Preservation**: All models receive project context for more relevant responses

### ğŸ”„ MultiAsk Mode

- **Parallel Querying**: Send your question to multiple LLM models simultaneously
- **Streaming Responses**: Watch responses appear in real-time as models generate them
- **Side-by-Side Comparison**: View all model responses in a responsive grid layout
- **Verdict Synthesis**: An optional verdict model analyzes all responses to identify consensus and differences
- **Follow-up Conversations**: Continue asking questions with full conversation context
- **Complete History**: See all past turns with questions, responses from every model, and verdicts

### ğŸ” Critique Chain Mode

A structured workflow for thoroughly vetted answers:

| Step                   | Description                                                                                        |
| ---------------------- | -------------------------------------------------------------------------------------------------- |
| 1. **Primary Model**   | Answers your question first                                                                        |
| 2. **Critique Models** | Multiple models critically evaluate the primary response for accuracy, completeness, and reasoning |
| 3. **Reviewer Model**  | Synthesizes all critiques, identifies consensus/disagreements, and provides a final verdict        |

- **Visual Progress**: See which step is currently active
- **Follow-up Support**: Continue with follow-up questions that include full context
- **History Persistence**: All steps are saved and visible when you return to the thread

### ğŸ§  Smart Memory System

- **Automatic Summarization**: Every 10 messages, an AI analyzes conversations and extracts:
  - **Summary**: Overview of project status and goals
  - **Key Facts**: Important information established in conversations
  - **Decisions**: Choices made with reasoning and dates
  - **Open Questions**: Unresolved items to address
- **Context Injection**: Project memory is included in prompts to all models
- **Manual Refresh**: Trigger memory updates on demand

### ğŸ¨ Modern UI/UX

- Beautiful dark theme with gradient accents
- Responsive sidebar with project and thread navigation
- Markdown rendering with syntax highlighting
- Real-time streaming animations
- Auto-expanding text input
- Loading states and smooth transitions

## ğŸš€ Quick Start

### Prerequisites

- **Node.js 18+** - [Download here](https://nodejs.org/)
- **OpenRouter API Key** - [Get one here](https://openrouter.ai/keys)
- **PostgreSQL Database** - For production deployment
- **Firebase Project** - For authentication ([Setup guide](https://firebase.google.com/))

### Installation

1. **Clone the repository**

   ```bash
   git clone https://github.com/dsk003/multimodelGPT.git
   cd multimodelGPT
   ```

2. **Install dependencies**

   ```bash
   npm install
   ```

3. **Set up environment variables**

   Create a `.env.local` file in the project root:

   ```env
   # Database
   DATABASE_URL="postgresql://user:password@localhost:5432/llmcouncil"

   # Firebase Admin (Server-side)
   FIREBASE_PROJECT_ID=your-project-id
   FIREBASE_CLIENT_EMAIL=your-client-email@project.iam.gserviceaccount.com
   FIREBASE_PRIVATE_KEY="-----BEGIN PRIVATE KEY-----\nYour key\n-----END PRIVATE KEY-----\n"

   # Firebase Client (Client-side)
   NEXT_PUBLIC_FIREBASE_API_KEY=your-api-key
   NEXT_PUBLIC_FIREBASE_AUTH_DOMAIN=your-project.firebaseapp.com
   NEXT_PUBLIC_FIREBASE_PROJECT_ID=your-project-id
   NEXT_PUBLIC_FIREBASE_STORAGE_BUCKET=your-project.appspot.com
   NEXT_PUBLIC_FIREBASE_MESSAGING_SENDER_ID=123456789
   NEXT_PUBLIC_FIREBASE_APP_ID=1:123456789:web:abcdef

   # OpenRouter API
   OPENROUTER_KEY=sk-or-v1-your-key-here

   # Cron Security (optional but recommended for production)
   CRON_SECRET=your-random-secret-here

   # Application URLs
   NEXT_PUBLIC_SITE_URL=http://localhost:3000
   NEXT_PUBLIC_BASE_URL=http://localhost:3000
   ```

4. **Run database migrations**

   ```bash
   npx prisma migrate deploy
   ```

5. **Sync models from OpenRouter**

   ```bash
   npx tsx scripts/seed-models.ts
   ```

6. **Start the development server**

   ```bash
   npm run dev
   ```

7. **Open the app**

   Navigate to [http://localhost:3000](http://localhost:3000) in your browser.

8. **Configure your models**

   - Click the **Settings** button (top right)
   - Add model IDs for the modes you want to use (models are synced automatically from OpenRouter)

9. **Create a Project & Start Comparing**
   - Click the **+** button in the sidebar to create a project
   - Click **MultiAsk** or **Critique Chain** to start a conversation
   - Ask your question and watch the magic happen!

## âš™ï¸ Configuration

### Setting Up Models

Click **Settings** in the top right corner to configure:

#### API Key

| Setting                | Description                                                        |
| ---------------------- | ------------------------------------------------------------------ |
| **OpenRouter API Key** | Your API key from [openrouter.ai/keys](https://openrouter.ai/keys) |

#### MultiAsk Tab

| Setting             | Description                                                                                          |
| ------------------- | ---------------------------------------------------------------------------------------------------- |
| **Models to Query** | Add model IDs to compare (e.g., `openai/gpt-4o`). Add multiple models to see responses side-by-side. |
| **Verdict Model**   | (Optional) A model that synthesizes all responses and identifies consensus/differences               |

#### Critique Chain Tab

| Setting             | Description                                                                             |
| ------------------- | --------------------------------------------------------------------------------------- |
| **Primary Model**   | The model that answers your question first                                              |
| **Critique Models** | Models that critically evaluate the primary response (add 2-3 for diverse perspectives) |
| **Reviewer Model**  | Model that synthesizes all critiques into a final assessment                            |

### Model Synchronization

**Automatic Updates:** The application automatically syncs available models from OpenRouter daily at 2:00 AM UTC. This ensures:

- âœ… You always see currently available models
- âœ… Deprecated models are automatically removed
- âœ… New models appear automatically
- âœ… Pricing information stays up-to-date

**Manual Sync:** To immediately sync models, run:

```bash
npx tsx scripts/seed-models.ts
```

See [MODELS_SYNC.md](MODELS_SYNC.md) for detailed documentation on the model synchronization system.

### Finding Model IDs

Browse available models at [openrouter.ai/models](https://openrouter.ai/models). Click any model to see its ID.

#### Popular Model IDs

| Model             | ID                                  | Best For                         |
| ----------------- | ----------------------------------- | -------------------------------- |
| GPT-4o            | `openai/gpt-4o`                     | Complex reasoning, analysis      |
| GPT-4o Mini       | `openai/gpt-4o-mini`                | Fast, cost-effective responses   |
| Claude 3.5 Sonnet | `anthropic/claude-3.5-sonnet`       | Writing, coding, analysis        |
| Claude 3.5 Haiku  | `anthropic/claude-3.5-haiku`        | Fast, concise responses          |
| Gemini 2.0 Flash  | `google/gemini-2.0-flash-exp:free`  | Free tier, general use           |
| Gemini 1.5 Pro    | `google/gemini-pro-1.5`             | Long context, detailed responses |
| Llama 3.3 70B     | `meta-llama/llama-3.3-70b-instruct` | Open source, capable             |
| DeepSeek V3       | `deepseek/deepseek-chat`            | Coding, reasoning                |
| Qwen 2.5 72B      | `qwen/qwen-2.5-72b-instruct`        | Multilingual, reasoning          |

## ğŸ“– How to Use

### Creating a Project

1. Click the **+** button in the sidebar
2. Enter a project name (e.g., "Research on AI", "Code Review", "Writing Help")
3. Click **Create**

### Starting a Conversation

1. Select your project in the sidebar
2. Click **MultiAsk** or **Critique Chain** button
3. Enter a title for your conversation
4. Start asking questions!

### MultiAsk Workflow

1. **Type your question** in the input box
2. **Press Enter** or click the send button
3. **Watch responses stream** in from all configured models
4. **Review the verdict** (if configured) for synthesis
5. **Ask follow-ups** to continue the conversation

### Critique Chain Workflow

1. **Type your question** in the input box
2. **Watch the primary model** answer first
3. **See critiques** from each critique model
4. **Read the final review** synthesizing all perspectives
5. **Ask follow-ups** for deeper exploration

### Viewing History

- **Select any thread** in the sidebar to see its complete history
- **All turns are preserved**: questions, model responses, verdicts/reviews
- **Continue where you left off** by asking a new question

### Managing Projects

- **Switch projects**: Click a project name in the sidebar
- **View threads**: Threads appear under the selected project
- **Delete threads**: Hover over a thread and click the trash icon
- **Delete projects**: Hover over a project and click the trash icon (deletes all threads too)

## ğŸ§  Project Memory System

### How It Works

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Your Conversations                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚ Message â”‚  â”‚ Message â”‚  â”‚ Message â”‚  â”‚ Message â”‚  ...    â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜        â”‚
â”‚       â”‚            â”‚            â”‚            â”‚              â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                          â”‚                                   â”‚
â”‚                          â–¼                                   â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚              â”‚   Every 10 Messages   â”‚                      â”‚
â”‚              â”‚   AI Summarization    â”‚                      â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚                          â”‚                                   â”‚
â”‚                          â–¼                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                   Project Memory                       â”‚  â”‚
â”‚  â”‚  â€¢ Summary: Project overview and status               â”‚  â”‚
â”‚  â”‚  â€¢ Facts: Key information established                 â”‚  â”‚
â”‚  â”‚  â€¢ Decisions: Choices made with reasoning             â”‚  â”‚
â”‚  â”‚  â€¢ Open Questions: Items to address                   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                          â”‚                                   â”‚
â”‚                          â–¼                                   â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚              â”‚   Injected into all   â”‚                      â”‚
â”‚              â”‚   future prompts      â”‚                      â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Memory Display

- **View memory** in the sidebar under the current project
- **Refresh memory** by clicking the refresh button
- **Memory updates** automatically every 10 messages

## ğŸ“ Project Structure

```
multimodelGPT/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â”œâ”€â”€ chat/route.ts              # OpenRouter API proxy
â”‚   â”‚   â”‚   â”œâ”€â”€ projects/                  # Project CRUD endpoints
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ route.ts               # List/Create projects
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ [id]/
â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ route.ts           # Get/Update/Delete project
â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ threads/route.ts   # List/Create threads
â”‚   â”‚   â”‚   â”‚       â””â”€â”€ memory/route.ts    # Get/Refresh memory
â”‚   â”‚   â”‚   â””â”€â”€ threads/
â”‚   â”‚   â”‚       â””â”€â”€ [id]/
â”‚   â”‚   â”‚           â”œâ”€â”€ route.ts           # Get/Update/Delete thread
â”‚   â”‚   â”‚           â””â”€â”€ messages/route.ts  # Get/Save messages
â”‚   â”‚   â”œâ”€â”€ globals.css
â”‚   â”‚   â”œâ”€â”€ layout.tsx
â”‚   â”‚   â””â”€â”€ page.tsx                       # Main app with routing
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ CritiqueChain.tsx              # Critique Chain workflow
â”‚   â”‚   â”œâ”€â”€ FollowUpInput.tsx              # Follow-up input component
â”‚   â”‚   â”œâ”€â”€ NewThreadModal.tsx             # Create thread modal
â”‚   â”‚   â”œâ”€â”€ ProjectSidebar.tsx             # Sidebar navigation
â”‚   â”‚   â”œâ”€â”€ ResponsePanel.tsx              # Model response display
â”‚   â”‚   â”œâ”€â”€ SettingsModal.tsx              # Settings configuration
â”‚   â”‚   â””â”€â”€ VerdictPanel.tsx               # Verdict/synthesis display
â”‚   â”œâ”€â”€ context/
â”‚   â”‚   â”œâ”€â”€ ModelsContext.tsx              # Model settings state
â”‚   â”‚   â””â”€â”€ ProjectContext.tsx             # Project/thread state
â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”œâ”€â”€ index.ts                       # SQLite connection & migrations
â”‚   â”‚   â””â”€â”€ schema.ts                      # Drizzle ORM schema
â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”œâ”€â”€ context-manager.ts             # Memory management
â”‚   â”‚   â””â”€â”€ conversation-utils.ts          # History reconstruction
â”‚   â””â”€â”€ types/
â”‚       â””â”€â”€ index.ts                       # TypeScript types
â”œâ”€â”€ data/                                  # SQLite database (auto-created)
â”‚   â””â”€â”€ multimodel.db
â”œâ”€â”€ package.json
â”œâ”€â”€ tailwind.config.ts
â””â”€â”€ tsconfig.json
```

## ğŸ—„ï¸ Database Schema

```sql
-- Projects: Top-level organization
projects (id, name, created_at, updated_at)

-- Project Memory: AI-generated context
project_memory (id, project_id, summary, facts, decisions, open_questions, updated_at)

-- Threads: Conversations within projects
threads (id, project_id, title, mode, created_at, updated_at)

-- Messages: Individual messages with turn grouping
messages (id, thread_id, project_id, role, content, model_used, turn_number, metadata, created_at)
```

## ğŸ› ï¸ Tech Stack

| Technology                                                   | Purpose                         |
| ------------------------------------------------------------ | ------------------------------- |
| [Next.js 16](https://nextjs.org/)                            | React framework with App Router |
| [TypeScript](https://www.typescriptlang.org/)                | Type-safe JavaScript            |
| [Tailwind CSS](https://tailwindcss.com/)                     | Utility-first styling           |
| [SQLite](https://www.sqlite.org/)                            | Local database storage          |
| [better-sqlite3](https://github.com/WiseLibs/better-sqlite3) | SQLite driver                   |
| [Drizzle ORM](https://orm.drizzle.team/)                     | Type-safe database queries      |
| [OpenRouter](https://openrouter.ai/)                         | Unified LLM API access          |
| [React Markdown](https://github.com/remarkjs/react-markdown) | Markdown rendering              |
| [remark-gfm](https://github.com/remarkjs/remark-gfm)         | GitHub Flavored Markdown        |

## ğŸ“ Usage Tips

### For Best Results

| Tip                   | Description                                                        |
| --------------------- | ------------------------------------------------------------------ |
| **Diverse Models**    | Use models from different providers for varied perspectives        |
| **Capable Verdict**   | Use a strong model (GPT-4o, Claude 3.5 Sonnet) as verdict/reviewer |
| **Project Per Topic** | Create separate projects for different research topics             |
| **Clear Questions**   | Be specific in your questions for better responses                 |
| **Follow Up**         | Use follow-up questions to drill deeper into topics                |

### Recommended Model Combinations

**For MultiAsk Comparison:**

- GPT-4o + Claude 3.5 Sonnet + Gemini 1.5 Pro
- GPT-4o-mini + Claude 3.5 Haiku + Llama 3.3 70B (cost-effective)

**For Critique Chain:**

- Primary: GPT-4o or Claude 3.5 Sonnet
- Critics: 2-3 models from different providers
- Reviewer: GPT-4o or Claude 3.5 Sonnet

## ğŸ› Troubleshooting

### Common Issues

| Issue                     | Solution                                          |
| ------------------------- | ------------------------------------------------- |
| **"API key invalid"**     | Ensure key starts with `sk-or-` and has credits   |
| **Models not responding** | Check model ID is correct at openrouter.ai/models |
| **Database errors**       | Delete `data/multimodel.db` to reset              |
| **Slow responses**        | Some models are slower; try faster variants       |
| **Memory not updating**   | Click "Refresh Memory" in sidebar                 |

### Reset Everything

```bash
# Delete the database to start fresh
rm -rf data/multimodel.db*

# Restart the server
npm run dev
```

## ğŸ”® Future Ideas

- [ ] Export conversations to Markdown/PDF
- [ ] Custom system prompts per project
- [ ] Model response rating/feedback
- [ ] Cost tracking per conversation
- [ ] Sharing threads with others
- [ ] Custom themes

## ğŸ“„ License

MIT License - feel free to use this project for any purpose.

---

<p align="center">
  <strong>Made with â¤ï¸ for the AI community</strong>
  <br>
  <a href="https://github.com/dsk003/multimodelGPT">GitHub</a> â€¢
  <a href="https://openrouter.ai/">OpenRouter</a>
</p>
